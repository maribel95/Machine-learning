{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fe82e5",
   "metadata": {},
   "source": [
    "<b>Alumnos</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6330cdc6",
   "metadata": {},
   "source": [
    "* Crespí Valero, Maribel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bdd1b",
   "metadata": {},
   "source": [
    "* Fortes Domínguez, Odilo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5bbeb",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e949be",
   "metadata": {},
   "source": [
    "En esta práctica el problema a resolver se basa en la creación de un modelo de aprendizaje automático que sea capaz de clasificar una palabra dada según pertenezca a la lengua inglesa o catalana.\n",
    "\n",
    "Para ello se nos provee de un dataset con aproximadamente 1000 palabras en inglés y 1000 en catalán (son las mismas palabras). Tiene tres columnas, donde dos de ellas son la palabra en cada idioma, y la restante es el id de la fila.\n",
    "\n",
    "El algoritmo a utilizar será un Support Vector Machine (SVM). SVM se basa en la idea de encontrar un hiperplano de separación entre dos clases de datos en un espacio de características de alta dimensión. Son muy efectivos en problemas de clasificación binaria y también pueden manejar problemas no lineales mediante técnicas de kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b87724",
   "metadata": {},
   "source": [
    "# Tratamiento del conjunto de datos\n",
    "\n",
    "El tratamiento del conjunto de datos es una etapa muy importante a la hora de atacar cualquier problema. No podremos obtener buenos resultados si los datos tampoco son buenos.\n",
    "\n",
    "Aunque los datos iniciales son los que son, podemos tratar de obtener nuevas características a partir de las ya existentes: seleccionar características relevantes, borrar características si vemos que no son relevantes, eliminar valores faltantes, corregir errores de datos y normalizar variables.\n",
    "\n",
    "Un buen tratamiento del conjunto de datos puede mejorar significativamente la precisión y rendimiento de los modelos de aprendizaje automático utilizados posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a0980",
   "metadata": {},
   "source": [
    "## Preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8094161",
   "metadata": {},
   "source": [
    "Primero de todo deberemos echar un vistazo al dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35add83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      catala     angles\n",
      "0       1         com         as\n",
      "1       3        seva        his\n",
      "2       4         que       that\n",
      "3       5         ell         he\n",
      "4       6         era        was\n",
      "..    ...         ...        ...\n",
      "983   996         nas       nose\n",
      "984   997      plural     plural\n",
      "985   998      còlera      anger\n",
      "986   999  reclamació      claim\n",
      "987  1000   continent  continent\n",
      "\n",
      "[988 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería pandas para poder cargar y modificar el dataset.\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos el dataset.\n",
    "df = pd.read_csv(\"data/data.csv\", delimiter=r\"\\s+\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f064f8f",
   "metadata": {},
   "source": [
    "Cabe mencionar que previamente hemos confirmado que todas las cadenas de texto están en minúscula, y además no hay valores nulos.\n",
    "\n",
    "Ahora bien, como podemos observar, la primera columna contiene lo que parece ser un identificador de columna. No nos es útil, por lo que procedemos a eliminarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d1f6b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         catala     angles\n",
      "0           com         as\n",
      "1          seva        his\n",
      "2           que       that\n",
      "3           ell         he\n",
      "4           era        was\n",
      "..          ...        ...\n",
      "983         nas       nose\n",
      "984      plural     plural\n",
      "985      còlera      anger\n",
      "986  reclamació      claim\n",
      "987   continent  continent\n",
      "\n",
      "[988 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Borramos la columna que contiene el id de las filas.\n",
    "df = df.drop('0', axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84aff7",
   "metadata": {},
   "source": [
    "Como ya sabemos, para poder realizar un entrenamiento con un SVM debemos poder partir el dataframe en Datos y Target. En este caso no hay presente ningún Target (todavía).\n",
    "\n",
    "Lo que haremos será transformar el dataframe para que haya una sola columna que contenga todas las palabras (de ambas lenguas), y una segunda columna que indique si es de un idioma o de otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ac30ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target\n",
      "0           com    cat\n",
      "1          seva    cat\n",
      "2           que    cat\n",
      "3           ell    cat\n",
      "4           era    cat\n",
      "..          ...    ...\n",
      "983         nas    cat\n",
      "984      plural    cat\n",
      "985      còlera    cat\n",
      "986  reclamació    cat\n",
      "987   continent    cat\n",
      "\n",
      "[988 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Vamos a tratar por separado catalán e inglés y asignar el Target, luego los combinaremos.\n",
    "df2 = df\n",
    "\n",
    "# Este tendrá sólo palabras catalanas y la columna Target contendrá el valor 'cat'.\n",
    "# La columna catala la llamaremos 'Palabras' para luego unificar ambos dataframes (las columnas deben tener el mismo nombre).\n",
    "df = df.drop('angles', axis=1)\n",
    "df = df.assign(Target=pd.Series(['cat'] * len(df)))\n",
    "df = df.rename(columns={'catala': 'Palabras'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09df7954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Palabras Target\n",
      "0           as    eng\n",
      "1          his    eng\n",
      "2         that    eng\n",
      "3           he    eng\n",
      "4          was    eng\n",
      "..         ...    ...\n",
      "983       nose    eng\n",
      "984     plural    eng\n",
      "985      anger    eng\n",
      "986      claim    eng\n",
      "987  continent    eng\n",
      "\n",
      "[988 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos lo mismo pero con las palabras inglesas.\n",
    "df2 = df2.drop('catala', axis=1)\n",
    "df2 = df2.assign(Target=pd.Series(['eng'] * len(df2)))\n",
    "df2 = df2.rename(columns={'angles': 'Palabras'})\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2ecb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Palabras Target\n",
      "0          com    cat\n",
      "1         seva    cat\n",
      "2          que    cat\n",
      "3          ell    cat\n",
      "4          era    cat\n",
      "..         ...    ...\n",
      "983       nose    eng\n",
      "984     plural    eng\n",
      "985      anger    eng\n",
      "986      claim    eng\n",
      "987  continent    eng\n",
      "\n",
      "[1976 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Unimos los dataframes.\n",
    "df = pd.concat([df, df2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7b04a",
   "metadata": {},
   "source": [
    "En teoría ya hemos acabado, pero se puede observar que aunque hay 1976 filas, la última tiene el id 987. Esto es porque se conserva el id automático previo a la fusión. Para solucionarlo resetearemos el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa316732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target\n",
      "0           com    cat\n",
      "1          seva    cat\n",
      "2           que    cat\n",
      "3           ell    cat\n",
      "4           era    cat\n",
      "...         ...    ...\n",
      "1971       nose    eng\n",
      "1972     plural    eng\n",
      "1973      anger    eng\n",
      "1974      claim    eng\n",
      "1975  continent    eng\n",
      "\n",
      "[1976 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cada fila obtendrá su propio id único.\n",
    "df = df.reset_index(level=0, drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95f44e",
   "metadata": {},
   "source": [
    "## Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6791",
   "metadata": {},
   "source": [
    "Llegados a este punto ya tenemos una estructura más acorde con lo que se necesita para realizar un entrenamiento. \n",
    "\n",
    "Sin embargo sólo tenemos una única característica, por lo que el resultado no será para nada bueno. \n",
    "\n",
    "Vamos a tratar de añadir características relevantes para proporcionar información adicional que el modelo pueda utilizar para tomar decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce1aa6",
   "metadata": {},
   "source": [
    "* Longitud de la palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970cbe6",
   "metadata": {},
   "source": [
    "* Número de vocales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed77441",
   "metadata": {},
   "source": [
    "* Contiene tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff2965",
   "metadata": {},
   "source": [
    "* Contiene combinaciones de letras exclusivas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc157e79",
   "metadata": {},
   "source": [
    "* Frecuencia de cada vocal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373d01b",
   "metadata": {},
   "source": [
    "Para algunos casos hemos creado ciertas funciones. Iremos mostrando uno a uno cada caso de adición de características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab462e",
   "metadata": {},
   "source": [
    "#### Longitud de la palabra:\n",
    "\n",
    "Simplemente aplicaremos la función len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40be202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target  Num_letras\n",
      "0           com    cat           3\n",
      "1          seva    cat           4\n",
      "2           que    cat           3\n",
      "3           ell    cat           3\n",
      "4           era    cat           3\n",
      "...         ...    ...         ...\n",
      "1971       nose    eng           4\n",
      "1972     plural    eng           6\n",
      "1973      anger    eng           5\n",
      "1974      claim    eng           5\n",
      "1975  continent    eng           9\n",
      "\n",
      "[1976 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Num_letras'] = df['Palabras'].apply(len)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e47f2e",
   "metadata": {},
   "source": [
    "#### Número de vocales:\n",
    "\n",
    "Creamos una función básica que cuente las vocales de una palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b17f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target  Num_letras  Num_vocales\n",
      "0           com    cat           3            1\n",
      "1          seva    cat           4            2\n",
      "2           que    cat           3            2\n",
      "3           ell    cat           3            1\n",
      "4           era    cat           3            2\n",
      "...         ...    ...         ...          ...\n",
      "1971       nose    eng           4            2\n",
      "1972     plural    eng           6            2\n",
      "1973      anger    eng           5            2\n",
      "1974      claim    eng           5            2\n",
      "1975  continent    eng           9            3\n",
      "\n",
      "[1976 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def contar_vocales(palabra):\n",
    "    vocales = ['a', 'e', 'i', 'o', 'u']\n",
    "    contador = 0\n",
    "    for letra in palabra:\n",
    "        if letra in vocales:\n",
    "            contador += 1\n",
    "    return contador\n",
    "\n",
    "df['Num_vocales'] = df['Palabras'].apply(contar_vocales)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234cf7c2",
   "metadata": {},
   "source": [
    "#### Contiene tilde:\n",
    "\n",
    "La función creada comprueba todos los posibles carácteres existentes que puedan llevar una tilde o similar (por ejemplo ü). Esta característica nos puede beneficiar ya que las palabras en inglés nunca llevan tilde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea7bc31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target  Num_letras  Num_vocales  Tilde\n",
      "0           com    cat           3            1      0\n",
      "1          seva    cat           4            2      0\n",
      "2           que    cat           3            2      0\n",
      "3           ell    cat           3            1      0\n",
      "4           era    cat           3            2      0\n",
      "...         ...    ...         ...          ...    ...\n",
      "1971       nose    eng           4            2      0\n",
      "1972     plural    eng           6            2      0\n",
      "1973      anger    eng           5            2      0\n",
      "1974      claim    eng           5            2      0\n",
      "1975  continent    eng           9            3      0\n",
      "\n",
      "[1976 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def contiene_tilde(palabra):\n",
    "\n",
    "    tildes = \"áéíóúÁÉÍÓÚàèìòùÀÈÌÒÙüÜ\"\n",
    "    for letra in palabra:\n",
    "        if letra in tildes:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['Tilde'] = df['Palabras'].apply(contiene_tilde)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826fceb9",
   "metadata": {},
   "source": [
    "#### Contiene combinaciones de letras exclusivas:\n",
    "\n",
    "No se puede ignorar que algunas combinaciones son mucho más recurrentes en una lengua que en otra. Por ejemplo 'th'. Concretamente añadiremos 3 combinaciones con las que sabemos que ocurre esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9213fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target  Num_letras  Num_vocales  Tilde  Contiene_qu  \\\n",
      "0           com    cat           3            1      0            0   \n",
      "1          seva    cat           4            2      0            0   \n",
      "2           que    cat           3            2      0            1   \n",
      "3           ell    cat           3            1      0            0   \n",
      "4           era    cat           3            2      0            0   \n",
      "...         ...    ...         ...          ...    ...          ...   \n",
      "1971       nose    eng           4            2      0            0   \n",
      "1972     plural    eng           6            2      0            0   \n",
      "1973      anger    eng           5            2      0            0   \n",
      "1974      claim    eng           5            2      0            0   \n",
      "1975  continent    eng           9            3      0            0   \n",
      "\n",
      "      Contiene_th  Contiene_ll  \n",
      "0               0            0  \n",
      "1               0            0  \n",
      "2               0            0  \n",
      "3               0            1  \n",
      "4               0            0  \n",
      "...           ...          ...  \n",
      "1971            0            0  \n",
      "1972            0            0  \n",
      "1973            0            0  \n",
      "1974            0            0  \n",
      "1975            0            0  \n",
      "\n",
      "[1976 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "def contiene_combinacion(combinacion,palabra):\n",
    "    if combinacion in palabra:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['Contiene_qu'] = df['Palabras'].apply(lambda x: contiene_combinacion(combinacion=\"qu\", palabra=x))\n",
    "df['Contiene_th'] = df['Palabras'].apply(lambda x: contiene_combinacion(combinacion=\"th\", palabra=x))\n",
    "df['Contiene_ll'] = df['Palabras'].apply(lambda x: contiene_combinacion(combinacion=\"ll\", palabra=x))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481af81",
   "metadata": {},
   "source": [
    "#### Frecuencia de cada vocal:\n",
    "\n",
    "Esta característica juega un papel muy importante (y lo sabemos porque sin ella los resultados eran bastante peores).\n",
    "\n",
    "Para efectuarla, primero cambiaremos todas las vocales con tilde por vocales sin ella y posteriormente tan sólo contaremos vocales. Crearemos una columna por vocal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031bf964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Palabras Target  Num_letras  Num_vocales  Tilde  Contiene_qu  \\\n",
      "0           com    cat           3            1      0            0   \n",
      "1          seva    cat           4            2      0            0   \n",
      "2           que    cat           3            2      0            1   \n",
      "3           ell    cat           3            1      0            0   \n",
      "4           era    cat           3            2      0            0   \n",
      "...         ...    ...         ...          ...    ...          ...   \n",
      "1971       nose    eng           4            2      0            0   \n",
      "1972     plural    eng           6            2      0            0   \n",
      "1973      anger    eng           5            2      0            0   \n",
      "1974      claim    eng           5            2      0            0   \n",
      "1975  continent    eng           9            3      0            0   \n",
      "\n",
      "      Contiene_th  Contiene_ll  A  E  I  O  U  \n",
      "0               0            0  0  0  0  1  0  \n",
      "1               0            0  1  1  0  0  0  \n",
      "2               0            0  0  1  0  0  1  \n",
      "3               0            1  0  1  0  0  0  \n",
      "4               0            0  1  1  0  0  0  \n",
      "...           ...          ... .. .. .. .. ..  \n",
      "1971            0            0  0  1  0  1  0  \n",
      "1972            0            0  1  0  0  0  1  \n",
      "1973            0            0  1  1  0  0  0  \n",
      "1974            0            0  1  0  1  0  0  \n",
      "1975            0            0  0  1  1  1  0  \n",
      "\n",
      "[1976 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "def quitar_tildes(palabra):\n",
    "    cambios = {'a': ['à', 'á'],\n",
    "               'e': ['è', 'é'],\n",
    "               'i': ['ì', 'í', 'ï'],\n",
    "               'o': ['ò', 'ó'],\n",
    "               'u': ['ù', 'ú', 'ü']\n",
    "                }\n",
    "    for clave, valores in cambios.items():\n",
    "        for valor in valores:\n",
    "            palabra = palabra.replace(valor, clave)\n",
    "\n",
    "    return palabra\n",
    "\n",
    "def contar_todas_las_vocales(palabra):\n",
    "    palabra = quitar_tildes(palabra)\n",
    "\n",
    "    vocales = \"aeiou\"\n",
    "    frecuencia_vocales = [0, 0, 0, 0, 0]  # inicializamos el vector con ceros\n",
    "\n",
    "    # recorremos cada caracter de la palabra\n",
    "    for caracter in palabra:\n",
    "        # si el caracter es una vocal, aumentamos el contador correspondiente\n",
    "        if caracter in vocales:\n",
    "            indice = vocales.index(caracter)\n",
    "            frecuencia_vocales[indice] += 1\n",
    "\n",
    "    return frecuencia_vocales\n",
    "\n",
    "df[[\"A\", \"E\", \"I\", \"O\", \"U\"]] = pd.DataFrame(df[\"Palabras\"].apply(contar_todas_las_vocales).tolist(), index=df.index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e58c1c",
   "metadata": {},
   "source": [
    "# Selección de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455ff01",
   "metadata": {},
   "source": [
    "Cuando más tarde obtengamos nuestro modelo, podremos generar un reporte que nos informa del accuracy, precision, recall y f1-score gracias a la librería classification_report de sci-kit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b840417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b385b53",
   "metadata": {},
   "source": [
    "Nosotros nos basaremos en el <b>accuracy</b> para evaluar y escoger el mejor modelo (cuanto más alto este valor, mejor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bafbff",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a565c2",
   "metadata": {},
   "source": [
    "Una vez ya tenemos un buen dataframe de datos con el que trabajar y una métrica seleccionada, es hora de realizar el entrenamiento del modelo.\n",
    "\n",
    "Primeramente vamos a dividir el dataframe: por un lado en las características a aprender, y por el otro lado el Target.\n",
    "\n",
    "#### Importante: 'Palabras'.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a8fb2",
   "metadata": {},
   "source": [
    "La única característica original del dataset es un String. Esto nos dificulta el entrenamiento, ya que la función fit del entrenamiento\n",
    "no acepta cadenas de texto. Para ello hay que vectorizar estos Strings, pero no vale la pena ya que el uso de esta característica no contribuye a ningún tipo de mejora sobre el accuracy del modelo.\n",
    "\n",
    "Por este motivo, no añadiremos la característica 'Palabras' a ningún conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b7d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['Num_letras', 'Num_vocales', 'Tilde','Contiene_qu', 'Contiene_th', 'Contiene_ll', 'A', 'E', 'I', 'O', 'U']]\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84751405",
   "metadata": {},
   "source": [
    "## Conjuntos de entrenamiento y test\n",
    "Hemos elegido que el 30% de los datos conformen el conjunto de test. Queremos asegurarnos de que el modelo es evaluado correctamente, y aún así nos quedarán bastantes datos para un entrenamiento adecuado.\n",
    "\n",
    "Fijaremos una seed para que el proceso nos dé siempre los mismos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "484bb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Establecemos el tamaño del conjunto de test y fijamos la seed.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560d6f2",
   "metadata": {},
   "source": [
    "Aunque el porcentaje del conjunto de test en cuanto a los datos totales es relativamente arbitrario (siempre suele rondar el 20-30%), existen ciertos hiperparámetros de SVM que dan lugar a un gran número de diferentes combinaciones, demasiadas si quisiéramos probarlas todas una a una.\n",
    "\n",
    "Para obtener la mejor combinación de hiperparámetros que nos dé el mayor accuracy y por tanto el mejor modelo posible (según nuestras métricas), combinaremos dos técnicas que nos permitirán obtener los valores óptimos de los hiperparámetros: <b>K-Fold</b> y <b>Grid Search</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055196eb",
   "metadata": {},
   "source": [
    "## Combinación de K-Fold con Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38258a",
   "metadata": {},
   "source": [
    "También conocido como <b>Nested Cross-Validation</b>, este algoritmo se basa en dos bucles anidados: el externo divide el conjunto de entrenamiento mediante K-Folding, y en el interno se realiza la búsqueda de los mejores hiperparámetros.\n",
    "\n",
    "Cabe resaltar que esta búsqueda no es absoluta, pues está limitada a los hiperparámetros que nosotros proponemos.\n",
    "\n",
    "Los hiperparámetros que propondremos serán:\n",
    "\n",
    "* Kernel: Lineal y Radial\n",
    "\n",
    "Realmente hemos probado también otros dos: Polinomial y Sigmoide, pero si se ponen los 4 juntos entonces el tiempo de ejecución se vuelve excesivamente largo. Para que sea fácil probar el programa entero sólo indicamos estos dos.\n",
    "\n",
    "* C: 1, 10, 100\n",
    "\n",
    "C controla la cantidad de tolerancia al error en la clasificación. Cuanto más alto el valor de C menor tolerancia al error y por lo tanto se obtiene un modelo más complejo, pues se ajusta más a los datos de entrenamiento, aunque también puede llevar a un sobreajuste del modelo. Para valores bajos, se ignoran ciertas muestras para dar mayor libertad al hiperplano solución.\n",
    "\n",
    "* Gamma: 0.1, 1, 10\n",
    "\n",
    "Gamma es un hiperparámetro propio del kernel Radial (RBF), y controla la distancia de influencia de una muestra. Para valores altos las muestras deben estar muy cerca para que se considere que pertenecen a la misma clase. Para valores bajos se es más permisivo, por lo que habrá más puntos agrupados con mayores distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf8a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.1, 1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efd8ab",
   "metadata": {},
   "source": [
    "Ahora crearemos nuestro objeto clasificador con la función GridSearchCV a la que pasamos varios parámetros:\n",
    "\n",
    "* estimator\n",
    "\n",
    "Aquí indicamos el algoritmo a utilizar, que es SVM. Pero deberemos poner SVC ya que es la implementación específica de SVM para problemas de clasificación binaria en scikit-learn.\n",
    "\n",
    "* param_grid\n",
    "\n",
    "Como dijimos, param_grid contiene los valores de hiperparámetros que vamos a probar.\n",
    "\n",
    "* cv\n",
    "\n",
    "Se usará la Cross-Validation por defecto, aunque si bien podríamos haber definido nosotros mismos un número exacto de divisiones para realizarla.\n",
    "\n",
    "* verbose\n",
    "\n",
    "Indica si queremos obtener información a medida que se realiza el GridSearch. Como no queremos, lo ponemos a 0.\n",
    "\n",
    "* scoring\n",
    "\n",
    "Indica qué métrica usará el GridSearch para juzgar si un modelo es mejor que otro. Como dijimos anteriormente, nosotros usaremos el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3f2dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=None, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af22db8",
   "metadata": {},
   "source": [
    "Ahora por fin realizaremos el entrenamiento. Los resultados los revisaremos en la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c0346d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100], &#x27;gamma&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100], &#x27;gamma&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c7d84",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f74016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.7035368597289804\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fc38c",
   "metadata": {},
   "source": [
    "Como podemos observar, el kernel que nos ha dado el mejor resultado (mayor accuracy) ha sido el Radial (rbf). Los hiperparámetros correspondientes son C=1 y gamma=0.1, por lo que se entiende que hay mucha tolerancia a errores (C) y que los puntos pertenecientes a una misma clase no están tan juntos como se podría (gamma).\n",
    "\n",
    "El accuracy ha sido del 70%, o lo que es lo mismo, 7 de cada 10 predicciones hechas por el modelo son correctas.\n",
    "\n",
    "Recordemos que el objetivo final era obtener un modelo que clasificara lo mejor posible una palabra dada según fuera de la lengua inglesa o catalana. Aquí lo tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe5af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "biel_moya = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ac6e4",
   "metadata": {},
   "source": [
    "Vamos a obtener los resultados finales con el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1d484ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.76      0.66      0.71       288\n",
      "         eng       0.72      0.81      0.76       305\n",
      "\n",
      "    accuracy                           0.74       593\n",
      "   macro avg       0.74      0.73      0.73       593\n",
      "weighted avg       0.74      0.74      0.73       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las predicciones de X_test.\n",
    "y_pred = biel_moya.predict(X_test)\n",
    "\n",
    "# Comparando las predicciones con el ground truth podremos ver\n",
    "# qué tan bien lo hace y revisar diferentes métricas.\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe083e",
   "metadata": {},
   "source": [
    "A partir del informe de clasificación proporcionado, se pueden sacar las siguientes conclusiones:\n",
    "\n",
    "* El modelo tiene un accuracy de 0.74 en general, lo que significa que el modelo es correcto en un 74% de las veces.\n",
    "    \n",
    "Sin embargo previamente habíamos visto que 'clf.best_score_' nos daba un accuracy de 0.703 (recordemos que habíamos indicado que la métrica usada para elegir fue el accuracy).<br>\n",
    "      \n",
    "Esto se debe a que GridSearchCV y classification_report usan métodos diferentes para calcular el accuracy.\n",
    "      \n",
    "En el primer caso, el accuracy se calcula como el número de predicciones correctas dividido entre el número total de predicciones, mientras que classification_report se basa en la matriz de confusión del modelo, y no sólo en el número total de predicciones correctas.\n",
    "\n",
    "* La precisión para la clase \"cat\" es de 0.76 y para la clase \"eng\" es de 0.72, lo que significa que el modelo es correcto en un 76% de las veces en las que se le da una muestra etiquetada como \"cat\", y un 72% de las veces en las que se le da una muestra etiquetada como \"eng\".\n",
    "\n",
    "\n",
    "* El recall para la clase \"cat\" es de 0.66, lo que significa que el modelo detecta el 66% de las muestras etiquetadas como \"cat\". En el caso de la clase \"eng\" el recall es de 0.81, por lo que el modelo detecta el 81% de las muestras etiquetadas como \"eng\".\n",
    "<br>\n",
    "\n",
    "* El puntaje F1 para ambas clases es mayor de 0.7. Esto significa que el modelo tiene una buena precisión y un buen recall para ambas clases.\n",
    "<br>\n",
    "\n",
    "* El modelo tiene un soporte total de 593 muestras (X_test), con 288 muestras etiquetadas como \"cat\" y 305 muestras etiquetadas como \"eng\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435ff0a",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Los resultados mostraron que el SVM tuvo una accuracy del 74% en la clasificación de las muestras del conjunto de datos de test.\n",
    "\n",
    "En general, se puede concluir que el SVM es una herramienta efectiva para resolver problemas de clasificación y es capaz de manejar conjuntos de datos con muchas características.\n",
    "\n",
    "Además, SVM tiene la ventaja de ser un modelo no paramétrico, lo que significa que no requiere la especificación de una función de forma explícita y puede adaptarse a diferentes formas de distribución de los datos. \n",
    "\n",
    "Sin embargo, es importante tener en cuenta que SVM puede ser sensible a la elección del kernel e hiperparámetros, y puede requerir un ajuste cuidadoso de éstos para obtener buenos resultados (de ahí la decisión de utilizar Grid Search).\n",
    "\n",
    "En resumen, SVM es una gran opción a considerar en problemas de clasificación.\n",
    "\n",
    "Finalmente de forma ajena al problema, podemos afirmar que esta práctica nos ha ayudado enormemente a aprender y reforzar los conocimientos obtenidos en esta asignatura."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
